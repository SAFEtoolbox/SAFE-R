dat_ks <- data.frame(x = unlist(xc[ii]),
y = KS_all[[ii]],
group = as.factor(rep(1:length(KS_all[[ii]])))
)
pp <- ggplot(data = dat_ks) + geom_line(mapping = aes(x=x, y=y)) +
geom_point(mapping = aes(x=x, y=y, colour = group), size = 2) +
scale_colour_grey(guide=FALSE) + xlab(x_labels[ii]) + ylab("KS") + ylim(0,1) +
theme_bw()
plot_list[[ii]] <- pp
}
n_col <- min(n_col, M)
n_row <- ceiling(M/n_col)
do.call("grid.arrange", c(plot_list, ncol=n_col))
return(KS_all)
}
KS_all <- pawn_plot_ks(YF, FU, FC, xc)
# INDEX
#
# Steps:
# TODO
#
# REFERENCES
#
# Pianosi, F. and Wagener, T. (2018), Distribution-based sensitivity
# analysis from a generic input-output sample, Env. Mod. & Soft., 108, 197-207.
#
# Pianosi, F. and Wagener, T. (2015), A simple and efficient method
# for global sensitivity analysis based on cumulative distribution
# functions, Env. Mod. & Soft., 67, 1-11.
#
# This script prepared by Francesca Pianosi and Fanny Sarrazin (for python version),
# Valentina Noacco for the SAFER package
# University of Bristol, 2020
# mail to: valentina.noacco@bristol.ac.uk
## Step 1 (load the packages)
library(caTools)
library(calibrater)
library(SAFER)
library(ggplot2)
library(gridExtra)
library(matrixStats)
## Step 2 (setup the Hymod model)
# Load data:
data(LeafCatch)
dat <- LeafCatch[1:365,]
# Define inputs:
DistrFun  <- "unif" # Parameter distribution
DistrPar  <- list( c(0, 400), c(0, 2), c(0, 1), c(0, 0.1), c(0.1, 1)) #Parameter ranges (from literature)
x_labels <- c("Sm", "beta", "alfa", "Rs", "Rf")
# Define output:
myfun <- "hymod_MulOut"
## Step 3 (sample inputs space)
SampStrategy <- "lhs" # Latin Hypercube
N <- 3000 # Number of samples
M <- length(DistrPar) # Number of inputs
X <- AAT_sampling(SampStrategy, M, DistrFun, DistrPar, N)
colnames(X) <- x_labels
## Step 4 (run the model)
Y_multi_out <- model_evaluation(myfun, X, dat = dat)  # size (N,2)
colnames(Y_multi_out) <- c("rmse", "bias", "mean", "st dev", "var", "max")
# Visualize input/output samples for maximum streamflow
scatter_plots(X,Y_multi_out[,6]) + ylab("max")
## Step 5 (apply PAWN)
n <- 10 # number of conditioning intervals
# choose output of interest
Y <- Y_multi_out[,6] # max streamflow
x_labels = c('Sm', 'beta', 'alfa', 'Rs', 'Rf')
#' This function computes the unconditional output Cumulative Distribution Funtions
#' (i.e. when all inputs vary) and the conditional CDFs (when one input is fixed to a given
#' conditioning interval, while the other inputs vary freely).
#'
#' The function splits the output sample to create the conditional output by calling internally
#' the function PAWN.pawn_split_sample.
#' The splitting strategy is an extension of the strategy for uniformy distributed inputs
#' described in Pianosi and Wagener (2018) to handle inputs sampled from any distribution.
#' (see help of PAWN.pawn_split_sample for further explanation).
#'
#' The sensitivity indices for the PAWN method (KS statistic) measures the distance between
#' these conditional and unconditional output CDFs
#' (see help of PAWN.pawn_indices for further details and reference).
#'
#' @param X matrix \code{(N, M)} set of inputs samples
#' @param Y matrix \code{(N, 1)} set of output samples
#' @param n scalar, number of conditional intervals (default: 10)
#'
#' @return List containing:
#' \itemize{
#'   \item \code{YF} vector \code{(P, 1)} values of Y at which the CDFs are given
#'   \item \code{FU} list of \code{M} elements, values of the empirical unconditional distribution \code{F(y)}
#'   \item \code{FC} list of lists, values of the empirical conditional output CDFs for each input and each conditioning interval.
#'   \code{FC[i]} is a list of n_eff[i] CDFs conditional to the i-th input.
#'   \code{FC[i][k]} is obtained by fixing the i-th input to its k-th conditioning interval (while the other
#'   inputs vary freely)
#'   }
#'   @export
pawn_CDF <- function(X, Y, n=10, dummy = FALSE, verbose = TRUE){
# This functions splits a generic input-output dataset to create the conditional samples
# for the approximation of PAWN sensitivity indices
pawn_samp <- pawn_split_sample(X, Y, n, verbose)
XX <- pawn_samp$XX
YY <- pawn_samp$YY
xc <- pawn_samp$xc
NC <- pawn_samp$NC
Xk <- pawn_samp$Xk
n_eff <- pawn_samp$n_eff
N <- nrow(X)
M <- ncol(X)
# Set points at which the CDFs will be evaluated:
YF <- as.vector(sort(unique(Y)))
# Compute conditional CDFs
# (bootstrapping is not used to assess conditional CDFs):
FC <- list(list())
for(ii in 1:M){ # loop over inputs
FC[[ii]] <- rep(list(NA),n_eff[ii])
for(kk in 1:n_eff[ii]){ # loop over conditioning intervals
FC[[ii]][[kk]] <- ecdf(YY[[ii]][[kk]])(YF)
}
}
# Initialize unconditional CDFs:
#FU <- list(list())
FU <- list()
# M unconditional CDFs are computed (one for each input), so that for
# each input the conditional and unconditional CDFs are computed using the
# same number of data points (when the number of conditioning intervals
# n_eff[i] varies across the inputs, so does the shape of the conditional
# outputs YY[i]).
# Determine the sample size for the unconditional output bootsize:
bootsize <- as.vector(unlist(lapply(NC,min)))
# bootsize is equal to the sample size of the conditional outputs NC, or
# its  minimum value across the conditioning intervals when the sample size
# varies across conditioning intervals as may happen when values of an
# input are repeated several times (more details on this in the Note in the
# help of the function).
# To reduce the computational time (the calculation of empirical CDF is
# costly), the unconditional CDF is computed only once for all inputs that
# have the same value of bootsize[ii].
bootsize_unique <- sort(unique(bootsize))
N_compute <- length(bootsize_unique) # number of unconditional CDFs that will
# be computed for each bootstrap resample
# Determine the sample size of the subsample for the dummy input.
# The sensitivity index for the dummy input will be estimated at this minimum sample size
# so to estimate the 'worst' approximation error of the sensitivity index
# across the inputs:
idx_bootsize_min <- NA # In case dummy = FALSE
if(dummy == TRUE){
bootsize_min <- min(bootsize) # we use the smaller sample size across
# inputs, so that the sensitivity index for the dummy input estimates
# the 'worst' approximation error of the sensitivity index across the
# inputs:
idx_bootsize_min <- match(bootsize_min,bootsize)
}
if(N_compute > 1 && verbose){
warning('The number of data points to estimate the conditional and
unconditional output varies across the inputs. The CDFs
for the dummy input were computed using the minimum sample
size to provide an estimate of the "worst" approximation
of the sensitivity indices across input.')
}
for(kk in 1:N_compute){
# Bootstrap resapling (Extract an unconditional sample of size
# bootsize_unique[kk] by drawing data points from the full sample Y
# without replacement
idx_bootstrap <- sample.int(N, bootsize_unique[kk], replace=FALSE)
# Compute unconditional CDF:
FUkk <- ecdf(Y[idx_bootstrap])(YF)
# Associate the FUkk to all inputs that require an unconditional
# output of size bootsize_unique[kk]:
idx_input <- which(bootsize == bootsize_unique[kk])
for(ii in 1:length(idx_input)){
FU[[idx_input[ii]]] <- FUkk
}
}
FC_dummy <- NA # In case dummy = FALSE
if(dummy == TRUE){
# Bootstrap again from unconditional sample (the size of the
# resample is equal to bootsize_min):
idx_dummy <- sample.int(N, bootsize_min, replace=FALSE)
# Compute empirical CDFs for the dummy input:
FC_dummy <- ecdf(Y[idx_dummy])(YF)
}
robj <- list(YF=YF,FU=FU,FC=FC,idx_bootsize_min=idx_bootsize_min,FC_dummy=FC_dummy)
return(robj)
}
#' This function computes and plots the Kolmogorov-Smirnov (KS) statistic
#' between conditional and unconditional output CDFs for each input and each
#' conditioning interval.
#'
#' The unconditional and conditional CDF are computed by the function [[pawn_CDF]]
#' See the help of [[pawn_CDF]] for further explanation.
pawn_plot_ks <- function(YF, FU, FC, xc, n_col=5, x_labels='', output_condition = allrange, par = list()){
#TODO add checks (n_col, etc...)
###########################################################################
# Calculate KS-statistic
###########################################################################
KS_all <- pawn_ks(YF, FU, FC, output_condition = allrange, par = list())
M <- length(KS_all)
###########################################################################
# Plot
###########################################################################
plot_list = list()
for(ii in 1:M){
dat_ks <- data.frame(x = unlist(xc[ii]),
y = KS_all[[ii]],
group = as.factor(rep(1:length(KS_all[[ii]])))
)
pp <- ggplot(data = dat_ks) + geom_line(mapping = aes(x=x, y=y)) +
geom_point(mapping = aes(x=x, y=y, colour = group), size = 2) +
scale_colour_grey(guide=FALSE) + xlab(x_labels[ii]) + ylab("KS") + ylim(0,1) +
theme_bw()
plot_list[[ii]] <- pp
}
n_col <- min(n_col, M)
n_row <- ceiling(M/n_col)
do.call("grid.arrange", c(plot_list, ncol=n_col))
return(KS_all)
}
#' This function plots the unconditional output Cumulative Distribution Funtions
#' (i.e. when all inputs vary) and the conditional CDFs (when one input is fixed
#' to a given conditioning interval, while the other inputs vary freely).
#'
#' The unconditional and conditional CDF are computed by the function [[pawn_CDF]]
#' See the help of [[pawn_CDF]] for further explanation.
#'
pawn_plot_CDF <- function(X, Y, n=10, n_col=5, y_label='output y', labelinput='', verbose = TRUE){
stopifnot(is.matrix(X), is.numeric(X), is.numeric(Y))
#TODO add extra checks (n_col, etc...)
###########################################################################
# Split the input sample
###########################################################################
pawn_samp <- pawn_split_sample(X, Y, n, verbose)
XX <- pawn_samp$XX
YY <- pawn_samp$YY
xc <- pawn_samp$xc
NC <- pawn_samp$NC
Xk <- pawn_samp$Xk
n_eff <- pawn_samp$n_eff
N <- nrow(X)
M <- ncol(X)
###########################################################################
# Compute CDFs
###########################################################################
pawnCDF <- pawn_CDF(X, Y, n, dummy=FALSE, verbose = 1)
YF <- pawnCDF$YF
FU <- pawnCDF$FU
FC <- pawnCDF$FC
###########################################################################
# Plot
###########################################################################
plot_list = list()
for(ii in 1:M){
dat_cond <- data.frame(x = rep(YF,n_eff[ii]),
y = unlist(FC[[ii]]),
group = rep(1:n_eff[ii],each=length(YF)),
clab = as.factor(round(rep(unlist(xc[ii]),each=length(YF)),1))
)
# check if the rounding kept the correct number of conditional CDFs
zz = 1
while(nlevels(dat_cond$clab) < nlevels(as.factor(dat_cond$group))){
dat_cond$clab = as.factor(round(rep(unlist(xc[ii]),each=length(YF)),1+zz))
zz = zz + 1
}
dat_uncond <- data.frame(x = rep(YF,M),
y = unlist(FU[[ii]]),
group = rep(1:M, each = length(YF))
)
pp <- ggplot(data = dat_cond) + geom_line(mapping = aes(x=x, y=y, colour = clab), size = 1) +
scale_colour_grey(name = "") + xlab(y_label) + ylab(labelinput[ii]) +
geom_line(data = dat_uncond, inherit.aes = FALSE, aes(x = x, y = y), size = 1, color = "red") +
geom_hline(yintercept = 1, linetype = "dashed", color = "black") +
ylim(0,1) +
theme_bw()
plot_list[[ii]] <- pp
}
n_col <- min(n_col, M)
n_row <- ceiling(M/n_col)
do.call("grid.arrange", c(plot_list, ncol=n_col))
robj <- list(YF=YF,FU=FU,FC=FC,xc=xc)
return(robj)
}
# Compute and plot conditional and unconditional CDFs:
pawn_cdf <- pawn_plot_CDF(X, Y, n=10, n_col=3, y_label='output y', labelinput=x_labels)
# Compute and plot KS statistics for each conditioning interval:
KS <- pawn_ks(YF, FU, FC)
YF <- pawn_cdf$YF
FU <- pawn_cdf$FU
FC <- pawn_cdf$FC
xc <- pawn_cdf$xc
# Compute and plot KS statistics for each conditioning interval:
KS <- pawn_ks(YF, FU, FC)
KS_all <- pawn_plot_ks(YF, FU, FC, xc)
KS_all <- pawn_plot_ks(YF, FU, FC, xc,n_col=5, x_labels = x_labels)
KS_all <- pawn_plot_ks(YF, FU, FC, xc,n_col=3, x_labels = x_labels)
library(SAFER)
?SAFER
require("knitr")
# opts_knit$set(root.dir = 'C:/Users/vn1197/OneDrive - University of opts_knit$set(root.dir = 'Bristol/proj_SAFEVAL/SAFER/safer_1.2_WillisRe/SAFER/tutorial') # Change this before running!
opts_knit$set(root.dir = 'C:/Users/vn1197/OneDrive - University of Bristol/proj_SAFEVAL/SAFER/safer_1.2.1/MunichRe')
library(caTools)
library(calibrater) # Install from tar file, also available at: https://people.maths.bris.ac.uk/~mazjcr/calibrater_0.51.tar.gz
library(SAFER) # Install from zip
library(ggplot2)
library(ggridges)
library(tidyr)
library(cowplot)
library(tidyquant)
library(matrixStats)
M <- 3 # Define number of input factors (if the model was run in another environment)
X <-  as.matrix(read.csv("Xd.csv", header = T, colClasses = c(rep("numeric",M)), fileEncoding="UTF-8-BOM"))
head(X) # Display first rows of the input factors to check format
n_out <- 14
Y <-  as.matrix(read.csv("Yd.csv", header = T, colClasses = c(rep("numeric",n_out)), fileEncoding="UTF-8-BOM"))
head(Y) # Display first rows of the outputs to check format
x_labels <- c("Vuln. Func.","Buffer","Disagg. Points") # Name of inputs
sz_tx <- 12 # Font size for plots
N <- length(Y) # Get number of samples
colnames(X) <- x_labels # Set column names
p1 <- scatter_plots(X, Y[,14], prnam = x_labels) + ylab("AAL") +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank())
p2 <- scatter_plots(X, Y[,13], prnam = x_labels) + ylab("2-year Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank())
p3 <- scatter_plots(X, Y[,5], prnam = x_labels) + ylab("200-yr Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank())
plot_grid(p1, p2, p3, nrow = 3)
X11()
x_labels <- c("Vuln. Func.","Buffer","Disagg. Points") # Name of inputs
sz_tx <- 12 # Font size for plots
N <- length(Y) # Get number of samples
colnames(X) <- x_labels # Set column names
p1 <- scatter_plots(X, Y[,14], prnam = x_labels) + ylab("AAL") +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank())
p2 <- scatter_plots(X, Y[,13], prnam = x_labels) + ylab("2-year Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank())
p3 <- scatter_plots(X, Y[,5], prnam = x_labels) + ylab("200-yr Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank())
plot_grid(p1, p2, p3, nrow = 3)
plot_grid(p1, p2, nrow = 2)
X11()
plot_grid(p1, p2, nrow = 2)
X11()
plot_grid(p2, p3, nrow = 2)
p2 <- scatter_plots(X, Y[,13], prnam = x_labels) + ylab("2-year Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank()) +
geom_smooth(se = TRUE)
p3 <- scatter_plots(X, Y[,5], prnam = x_labels) + ylab("200-yr Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank()) +
geom_smooth(se = TRUE)
X11()
plot_grid(p2, p3, nrow = 2)
X11()
plot_grid(p2, p3, nrow = 2)
p2 <- scatter_plots(X, Y[,13], prnam = x_labels) + ylab("2-year Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank())
p3 <- scatter_plots(X, Y[,5], prnam = x_labels) + ylab("200-yr Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank())
X11()
plot_grid(p2, p3, nrow = 2)
X11()
plot_grid(p2, p3, nrow = 2)
p2 <- scatter_plots(X, Y[,13], prnam = x_labels) + ylab("2-year Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank()) +
geom_smooth(se = TRUE)
p3 <- scatter_plots(X, Y[,5], prnam = x_labels) + ylab("200-yr Loss")  +
theme(text = element_text(size=sz_tx)) + theme(axis.title.x=element_blank()) +
geom_smooth(se = TRUE)
X11()
plot_grid(p2, p3, nrow = 2)
n_groups <- 5; # Number of groups into which the output is splitted, default = 10
rsa_gr_AAL <- RSA_indices_groups(X, Y[,14], n_groups)
# Outputs
mvd_AAL <- rsa_gr_AAL$mvd_median # median mvd: maximum vertical distance between CDFs (sensitivity index)
idx_AAL <- rsa_gr_AAL$idx # idx: index which divides the output into different groups
Yk_AAL <- rsa_gr_AAL$Yk # Yk: output limit of each group
rsa_gr_2yr <- RSA_indices_groups(X, Y[,13], n_groups)
# Outputs
mvd_2yr <- rsa_gr_2yr$mvd_median # median mvd: maximum vertical distance between CDFs (sensitivity index)
idx_2yr <- rsa_gr_2yr$idx # idx: index which divides the output into different groups
Yk_2yr <- rsa_gr_2yr$Yk # Yk: output limit of each group
rsa_gr_200yr <- RSA_indices_groups(X, Y[,5], n_groups)
# Outputs
mvd_200yr <- rsa_gr_200yr$mvd_median # median mvd: maximum vertical distance between CDFs (sensitivity index)
idx_200yr <- rsa_gr_200yr$idx # idx: index which divides the output into different groups
Yk_200yr <- rsa_gr_200yr$Yk # Yk: output limit of each group
p1 <- boxplot1(mvd_AAL, prnam = x_labels) + ylab("Sensitivity Index") + ggtitle('AAL') +
theme(plot.title = element_text(hjust = 0.5))
p2 <- boxplot1(mvd_2yr, prnam = x_labels) + ylab("Sensitivity Index") + ggtitle('2-year Loss') +
theme(plot.title = element_text(hjust = 0.5))
p3 <- boxplot1(mvd_200yr, prnam = x_labels) + ylab("Sensitivity Index") + ggtitle('200-year Loss') +
theme(plot.title = element_text(hjust = 0.5))
plot_grid(p1, p2, p3, nrow = 3)
Nboot <- 100 # Number of resamples used for bootstrapping
rsatgr100_AAL <- RSA_indices_groups(X, Y[,14], n_groups, Nboot = Nboot) # By adding the extra
# argument `Nboot` to the function `RSA_indices_groups` bootstrapping is performed,
# 'alfa' is the scalar significance level for the confidence intervals estimated by bootstrapping
mvd_median_AAL <- rsatgr100_AAL$mvd_median
# Compute mean and confidence intervals of the sensitivity indices across the
# bootstrap resamples:
alfa <- 0.05 # Significance level for the confidence intervals estimated by bootstrapping
mvd_m_AAL <- colMeans(mvd_median_AAL) # median
mvd_lb_AAL <-  colQuantiles(mvd_median_AAL,probs=alfa/2) # Lower bound
mvd_ub_AAL <- colQuantiles(mvd_median_AAL,probs=1-alfa/2) # Upper bound
rsatgr100_2yr <- RSA_indices_groups(X, Y[,13], n_groups, Nboot = Nboot)
mvd_median_2yr <- rsatgr100_2yr$mvd_median
mvd_m_2yr <- colMeans(mvd_median_2yr) # median
mvd_lb_2yr <-  colQuantiles(mvd_median_2yr,probs=alfa/2) # Lower bound
mvd_ub_2yr <- colQuantiles(mvd_median_2yr,probs=1-alfa/2) # Upper bound
rsatgr100_200yr <- RSA_indices_groups(X, Y[,5], n_groups, Nboot = Nboot)
mvd_median_200yr <- rsatgr100_200yr$mvd_median
mvd_m_200yr <- colMeans(mvd_median_200yr) # median
mvd_lb_200yr <-  colQuantiles(mvd_median_200yr,probs=alfa/2) # Lower bound
mvd_ub_200yr <- colQuantiles(mvd_median_200yr,probs=1-alfa/2)
p1 <- boxplot1(mu = mvd_m_AAL, lb = mvd_lb_AAL, ub = mvd_ub_AAL, prnam = x_labels) + ylab("Sensitivity Index") +
ggtitle('AAL') + theme(plot.title = element_text(hjust = 0.5))
p2 <- boxplot1(mu = mvd_m_2yr, lb = mvd_lb_2yr, ub = mvd_ub_2yr, prnam = x_labels) + ylab("Sensitivity Index") +
ggtitle('2-year Loss') + theme(plot.title = element_text(hjust = 0.5))
p3 <- boxplot1(mu = mvd_m_200yr, lb = mvd_lb_200yr, ub = mvd_ub_200yr, prnam = x_labels) + ylab("Sensitivity Index") +
ggtitle('200-year Loss') + theme(plot.title = element_text(hjust = 0.5))
plot_grid(p1, p2, p3, nrow = 3)
X11()
plot_grid(p2, p3, nrow = 2)
setwd("C:/Users/valen/OneDrive - University of Bristol/proj_SAFEVAL/SAFER/safer_1.2.1/SAFER/R")
library(SAFER)
# Setup the model and define input ranges
fun_test  <- "ishigami_homma_function"
M <- 3
distr_fun <- "unif"
distrpar <-  c(-pi, pi)
# Compute the exact values of the output variance (V) and of
# the first-order (Si_ex) and total-order (STi_ex)
# variance-based sensitivity indices (this is possible in this
# very specific case because V, Si_ex and STi_ex can be computed
# analytically)
ihfun <- ishigami_homma_function(runif(M))
Si_ex <- attributes(ihfun)$Si_ex
STi_ex <- attributes(ihfun)$STi_ex
SampStrategy <- "lhs"
N <- 3000
X <- AAT_sampling(SampStrategy, M, distr_fun, distrpar, 2 * N)
# Apply resampling strategy for the efficient approximation of the indices:
XABC <- vbsa_resampling(X)
# Run the model and compute selected model output at sampled parameter
# sets:
YA <- model_execution(fun_test, XABC$XA) # size (N,1)
YB <- model_execution(fun_test, XABC$XB) # size (N,1)
YC <- model_execution(fun_test, XABC$XC) # size (N*M,1)
# Compute main (first-order) and total effects:
ind <- vbsa_indices(YA, YB, YC)
Si <- ind[1,]
STi <- ind[2,]
#
dev.new()
par(mfrow = c(1, 2))
boxplot2(Si, Si_ex, leg = c("estimated", "exact"), main = "Si")
boxplot2(STi, STi_ex, leg = c("estimated", "exact"), main = "STi")
# Analyze convergence of sensitivity indices:
NN <- seq(N / 5, N, by = N/5)
conv <- vbsa_convergence(c(YA, YB, YC), M, NN)
Si <- conv$Si
STi <- conv$STi
dev.new()
par(mfrow = c(1, 2))
plot_convergence(NN * (M + 2), Si, ex = Si_ex, xlab = "model evals", ylab = "main effect")
plot_convergence(NN * (M + 2), STi, ex = STi_ex, xlab = "model evals", ylab = "total effect")
library(SAFER)
## Step 2: setup the model and define input ranges
# Load data:
data(LeafCatch)
dat <- LeafCatch[1:365,]
# Define input distribution and ranges:
M  <- 5 # number of uncertain parameters (Sm beta alfa Rs Rf )
DistrFun  <- "unif" # Parameter distribution
DistrPar  <- list( c(0, 400), c(0, 2), c(0, 1), c(0, 0.1), c(0.1, 1)) #Parameter ranges (from literature)
x_labels <- c("Sm", "beta", "alfa", "Rs", "Rf")
## Step 3: Compute first-order and total-order variance-based indices
myfun <- "hymod_nse"
# Sample parameter space using the resampling strategy proposed by
# (Saltelli, 2008; for reference and more details, see help of functions
# vbsa_resampling and vbsa_indices)
SampStrategy <- "lhs"
N <- 3000 # Base sample size.
# Comment: the base sample size N is not the actual number of input
# samples that will be executed In fact, because of the resampling
# strategy, the total number of model executions to compute the two
# variance-based indices is equal to N*(M+2)
X <- AAT_sampling(SampStrategy, M, DistrFun, DistrPar, 2 * N)
XABC <- vbsa_resampling(X)
YA <- model_execution(myfun, XABC$XA, dat = dat) # size (N,1)
YB <- model_execution(myfun, XABC$XB, dat = dat) # size (N,1)
YC <- model_execution(myfun, XABC$XC, dat = dat) # size (N*M,1)
ind <- vbsa_indices(YA, YB, YC)
Si <- ind[1,]
STi <- ind[2,]
names(Si) <- x_labels
names(STi) <- x_labels
# plot main and total separately
dev.new()
par(mfrow = c(1, 2))
boxplot1(Si, prnam = x_labels) + ylab("Si")
boxplot1(STi, prnam = x_labels) + ylab("STi")
library(ggplot2)
dev.new()
par(mfrow = c(1, 2))
boxplot1(Si, prnam = x_labels) + ylab("Si")
boxplot1(STi, prnam = x_labels) + ylab("STi")
dev.new()
p1 <- boxplot1(Si, prnam = x_labels) + ggtitle("Si")
p2 <- boxplot1(STi, prnam = x_labels) + ggtitle("STi")
plot_grid(p1, p2, nrow = 2)
library(cowplot)
dev.new()
p1 <- boxplot1(Si, prnam = x_labels) + ggtitle("Si")
p2 <- boxplot1(STi, prnam = x_labels) + ggtitle("STi")
plot_grid(p1, p2, nrow = 2)
